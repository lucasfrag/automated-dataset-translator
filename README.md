# ğŸŒ Automated Dataset Translator

> Automatically translate structured datasets (CSV, JSON, JSONL, TSV, Parquet) using LLMs via Ollama â€” with caching, parallelism, checkpointing, and retry support.

---

## âœ¨ Features

* ğŸŒ Translate dataset **content automatically using LLMs**
* ğŸ“‚ Supports multiple formats:

  * CSV
  * JSON
  * JSONL
  * TSV
  * Parquet
* ğŸ§  Uses **local models via Ollama**
* âš¡ Parallel processing (multi-threaded)
* ğŸ’¾ Persistent cache (SQLite) â€” avoids retranslating identical text
* ğŸ” Automatic retry with exponential backoff
* â¸ï¸ Checkpoint system â€” resume interrupted translations
* ğŸ“Š Progress bars with tqdm
* ğŸ¯ Select specific columns to translate
* ğŸ”’ Safe and deterministic output generation

---

## ğŸ“¦ Installation

Clone the repository:

```bash
git clone https://github.com/lucasfrag/auto-dataset-translator.git
cd auto-dataset-translator
```

Install dependencies:

```bash
pip install -r requirements.txt
```

Install Ollama:

https://ollama.ai

Pull a model:

```bash
ollama pull llama3.1:8b
```

---

## ğŸš€ Usage

Basic example:

```bash
python main.py \
  --input dataset.csv \
  --output dataset_pt.csv \
  --columns text title description \
  --model llama3.1:8b \
  --target-lang Portuguese
```

---

## âš¡ Parallel processing

Use multiple workers:

```bash
python main.py \
  -i dataset.csv \
  -o dataset_pt.csv \
  -c text title description \
  -m llama3.1:8b \
  -t Portuguese \
  -w 4
```

---

## ğŸ” Force retranslation

Ignore cache and checkpoint:

```bash
python main.py ... --force
```

---

## ğŸ§  How it works

Pipeline:

```
Load dataset
   â†“
Check cache
   â†“
Translate using Ollama
   â†“
Save to cache
   â†“
Save checkpoint
   â†“
Write output dataset
```

---

## ğŸ’¾ Cache system

Cache is stored in:

```
translation_cache.db
```

Benefits:

* Avoid retranslating identical text
* Massive performance improvements
* Persistent across runs

---

## â¸ï¸ Checkpoint system

Checkpoint is stored in:

```
checkpoint.db
```

Allows:

* Resume interrupted runs
* Process very large datasets safely
* Crash recovery

---

## ğŸ¯ Example

Input:

```csv
text,title
Hello world,Greeting
Machine learning is amazing,Statement
```

Output:

```csv
text,title
OlÃ¡ mundo,SaudaÃ§Ã£o
Aprendizado de mÃ¡quina Ã© incrÃ­vel,DeclaraÃ§Ã£o
```

---

## âš™ï¸ Arguments

| Argument              | Description                 |
| --------------------- | --------------------------- |
| `--input`, `-i`       | Input dataset               |
| `--output`, `-o`      | Output dataset              |
| `--columns`, `-c`     | Columns to translate        |
| `--model`, `-m`       | Ollama model                |
| `--target-lang`, `-t` | Target language             |
| `--source-lang`, `-s` | Source language (optional)  |
| `--workers`, `-w`     | Parallel workers            |
| `--force`             | Ignore cache and checkpoint |
| `--reset-cache`       | Delete cache                |
| `--reset-checkpoint`  | Delete checkpoint           |
| `--max-retries`       | Retry attempts              |
| `--retry-delay`       | Base retry delay            |

---

## âš¡ Performance

Features designed for scalability:

* Parallel processing
* Persistent caching
* Checkpoint resume
* Thread-safe SQLite backend

---

## ğŸ› ï¸ Requirements

* Python 3.9+
* Ollama

---

## ğŸ“œ License

MIT License

---

## â­ If you like this project, consider giving it a star!
